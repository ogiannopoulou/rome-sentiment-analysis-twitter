{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac6afac",
   "metadata": {},
   "source": [
    "# Weather Sentiment Analysis Project\n",
    "\n",
    "Welcome to this beginner-friendly NLP project! We will build a text classifier to understand how people feel about the weather.\n",
    "\n",
    "## What we will learn:\n",
    "1. **Text Preprocessing**: Cleaning up raw text data.\n",
    "2. **Vectorization (TF-IDF)**: Converting text into numbers the computer can understand.\n",
    "3. **Model Training**: Teaching a Machine Learning model to recognize patterns.\n",
    "4. **Prediction**: Testing our model on new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Check if data exists\n",
    "try:\n",
    "    df = pd.read_csv('data/weather_sentiment_samples.csv')\n",
    "    print(\"✅ Data loaded successfully!\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Data file not found. Create it first or update the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9dcab",
   "metadata": {},
   "source": [
    "## Step 1: Explore the Data\n",
    "Let's look at how many samples we have for each sentiment (positive, negative, neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].value_counts())\n",
    "\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5f837",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data for Training\n",
    "We need to split our data into training (for learning) and testing (for evaluation) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969d8d5",
   "metadata": {},
   "source": [
    "## Step 3: Vectorization (TF-IDF)\n",
    "Computers works with numbers, not words. We use **TF-IDF (Term Frequency-Inverse Document Frequency)** to convert text into numerical vectors.\n",
    "- **TF**: How often a word appears in a document.\n",
    "- **IDF**: How rare a word is across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c705a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit (learn vocabulary) and transform (convert to numbers) the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the vocabulary learned from training)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Shape of training matrix:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c465166",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "We'll use **Naive Bayes**, a simple yet effective algorithm for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"✅ Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27a1d9",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Model\n",
    "Let's see how well it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c028b",
   "metadata": {},
   "source": [
    "## Step 6: Test on New Sentences\n",
    "Now for the fun part! Let's test it with your own weather descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = [\n",
    "    \"I absolutely love this warm sunshine!\",\n",
    "    \"The thunder is scary and I hate it.\",\n",
    "    \"It is partly cloudy today.\",\n",
    "    \"Freezing cold weather makes me miserable.\"\n",
    "]\n",
    "\n",
    "new_vectors = vectorizer.transform(new_sentences)\n",
    "predictions = model.predict(new_vectors)\n",
    "\n",
    "for sentence, sentiment in zip(new_sentences, predictions):\n",
    "    print(f\"Sentence: '{sentence}' -> Sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
